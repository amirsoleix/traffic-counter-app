import subprocess
import sys
import os

def install(package):
    subprocess.check_call([sys.executable, "-m", "pip", "install", package])

import altair as alt
import numpy as np
import pandas as pd
import pydeck as pdk
import streamlit as st
import datetime
import plotly.express as px
import plotly.graph_objects as go
from persiantools.jdatetime import JalaliDate

st.set_page_config(page_title="Traffic Counter Data", page_icon="ðŸ˜Ž")

with open("./style.css") as css:
    st.markdown( f'<style>{css.read()}</style>' , unsafe_allow_html= True)

@st.cache_resource
def load_data():
    path = "data/data.csv.zip"
    if not os.path.isfile(path):
        path = "https://github.com/amirsoleix/traffic-counter-app/blob/master/data/data.csv.zip"

    data = pd.read_csv(
        path,
        names = [
            'road code', 'road name', 'start time', 'end time', 'operation length (minutes)', 'class 1', 'class 2',
            'class 3', 'class 4', 'class 5', 'estimated number', 'province', 'start city', 'end city', 'edge name'
        ],
        skiprows=1,
        usecols=[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 15, 16, 17, 18, 19]
    )
    data['start date'] = data['start time'].apply(lambda x: JalaliDate(
        int(x.split(' ')[0].split('/')[0]),
        int(x.split(' ')[0].split('/')[1]),
        int(x.split(' ')[0].split('/')[2])
    ))
    data['end date'] = data['end time'].apply(lambda x: JalaliDate(
        int(x.split(' ')[0].split('/')[0]),
        int(x.split(' ')[0].split('/')[1]),
        int(x.split(' ')[0].split('/')[2])
    ))

    return data

@st.cache_resource
def load_coordinates():
    path = "data/coordinates.csv.zip"
    if not os.path.isfile(path):
        path = "https://github.com/amirsoleix/traffic-counter-app/blob/master/data/coordinates.csv.zip"

    coordinates = pd.read_csv(
        path,
        names=[
            "city",
            "lat",
            "lon"
        ],
        skiprows=1,
        usecols=[0, 1, 2]
    )

    return coordinates

@st.cache_resource
def load_test():
    path = "data/hypothesis-test.csv"
    if not os.path.isfile(path):
        path = "https://github.com/amirsoleix/traffic-counter-app/blob/master/data/hypothesis-test.csv"

    coordinates = pd.read_csv(
        path,
        names=[
            "city",
            "entries"
        ],
        skiprows=1,
        usecols=[0, 1]
    )

    return coordinates

@st.cache_resource
def load_population():
    path = "data/population.csv.zip"
    if not os.path.isfile(path):
        path = "https://github.com/amirsoleix/traffic-counter-app/blob/master/data/population.csv.zip"
    
    population = pd.read_csv(
        path,
        names=[
            "city",
            "population"
        ],
        skiprows=1,
        usecols=[0, 1]
    )

    return population

@st.cache_resource
def cities_chart(data, cities, graph_title):
    years = [
        [JalaliDate(1395, 12, 20), JalaliDate(1396, 1, 18)],
        [JalaliDate(1396, 12, 20), JalaliDate(1397, 1, 18)],
        [JalaliDate(1397, 12, 20), JalaliDate(1398, 1, 18)],
        [JalaliDate(1398, 12, 20), JalaliDate(1399, 1, 18)],
        [JalaliDate(1399, 12, 20), JalaliDate(1400, 1, 18)],
        [JalaliDate(1400, 12, 20), JalaliDate(1401, 1, 18)],
        [JalaliDate(1401, 12, 20), JalaliDate(1402, 1, 18)],
    ]

    # Initialize the DataFrame with dynamic city names
    df = pd.DataFrame(columns=["Year"] + cities)

    for year in years:
        count = []
        for city in cities:
            total_count = int(data[(data['start date'] >= year[0]) & (data['end date'] <= year[1]) & (data['end city'] == city)]['class 1'].sum()) + int(data[(data['start date'] >= year[0]) & (data['end date'] <= year[1]) & (data['end city'] == city)]['class 2'].sum())
            count.append(total_count)
        year_data = [year[0].year + 1] + count
        df = pd.concat([df, pd.DataFrame([year_data], columns=["Year"] + cities)])

    # Plotting the data for each city
    fig = go.Figure()
    colors = ['indianred', 'lightsalmon', 'lightseagreen']  # You can extend this list for more cities.
    for idx, city in enumerate(cities):
        fig.add_trace(go.Bar(
            x=df['Year'],
            y=df[city],
            name=city,
            marker_color=colors[idx % len(colors)]
        ))

    fig.update_layout(
        barmode='group',
        xaxis_tickangle=0,
        title=graph_title,
        xaxis_title="Year",
        yaxis_title="Incoming Vehicle Count",
    )

    # Display the chart in Streamlit
    st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})

@st.cache_data
def find_dates():
    dates = []
    for year in range(1399, 1403):
        for month in [1, 12]:
            if year == 1402 and month == 12:
                continue
            if month == 12:
                for day in range(20, 31):
                    try:
                        JalaliDate(year, month, day)
                        dates.append(f"{year}-{month}-{day}")
                    except:
                        pass
            if month == 1:
                for day in range(1, 20):
                    try:
                        JalaliDate(year, month, day)
                        dates.append(f"{year}-{month}-{day}")
                    except:
                        pass
    return dates

@st.cache_data
def city_input(data, start_date, end_date):
    start_date = JalaliDate(
        int(start_date.split("-")[0]), int(start_date.split("-")[1]), int(start_date.split("-")[2]
    ))
    end_date = JalaliDate(
        int(end_date.split("-")[0]), int(end_date.split("-")[1]), int(end_date.split("-")[2]
    ))
    data = data[(data["start date"] >= start_date) & (data["end date"] <= end_date)]
    city_input = pd.DataFrame(columns=["date", "city", "input", "output", "net", "tourist", "province"])
    cities = data["start city"].unique()
    date_range = pd.date_range(start_date.to_gregorian(), end_date.to_gregorian())
    jalali_range = [JalaliDate(date) for date in date_range]

    for city in cities:
        for date in jalali_range:
            city_input = pd.concat([city_input, pd.DataFrame({
                "date": [date],
                "city": [city],
                "input": [0],
                "output": [0],
                "net": [0],
                "tourist": [0],
                "province": [data[data["start city"] == city]["province"].values[0]]
            })])

    for _, row in data.iterrows():
        city_input.loc[ (city_input["city"] == row["start city"]) & (city_input["date"] == row["start date"]), "output"] += row["class 1"]
        city_input.loc[ (city_input["city"] == row["end city"]) & (city_input["date"] == row["end date"]), "input"] += row["class 1"]

    city_input["net"] = city_input["input"] - city_input["output"]
    city_input["tourist"] = city_input["net"].apply(lambda x: abs(x))
    city_input = city_input.groupby("city").agg({
        "input": "sum",
        "output": "sum",
        "net": "sum",
        "tourist": "sum",
        "province": "first"
    }).reset_index()
    city_input = city_input.merge(population, on="city", how="left")
    city_input.sort_values(by=['tourist'], inplace=True, ascending=False)
    city_input.reset_index(inplace=True)

    return city_input

def map(data, lat, lon, zoom):
    st.write(
        pdk.Deck(
            map_style="mapbox://styles/mapbox/light-v9",
            initial_view_state={
                "latitude": lat,
                "longitude": lon,
                "zoom": zoom,
                "pitch": 50,
            },
            layers=[
                pdk.Layer(
                    "HexagonLayer",
                    data=data,
                    get_position=["lon", "lat"],
                    get_elevation_weight="tourist",
                    get_color_weight="tourist",
                    color_range=[
                        [215,48,39],
                        [252,141,89],
                        [254,224,139],
                        [217,239,139],
                        [145,207,96],
                        [26,152,80]
                    ],
                    radius=5000,
                    elevation_scale=6,
                    opacity=0.8,
                    elevation_range=[0, 8000],
                    pickable=True,
                    extruded=True,
                ),
            ],
        )
    )

@st.cache_data
def aggregate_data(aggregate_data):
    aggregate_data["input per capita"] = aggregate_data["input"] / (aggregate_data["population"] + 1)
    aggregate_data["output per capita"] = aggregate_data["output"] / (aggregate_data["population"] + 1)
    aggregate_data["net per capita"] = aggregate_data["net"] / (aggregate_data["population"] + 1)
    aggregate_data["tourist per capita"] = aggregate_data["tourist"] / (aggregate_data["population"] + 1)
    return aggregate_data

@st.cache_data
def dbscan(data, year):
    from sklearn.cluster import DBSCAN
    from sklearn.preprocessing import StandardScaler

    data = data[~data["city"].isin([
        'Ghazvin',
        'Gilan Border',
        'Golestan Forest',
        'Imamzadeh Hashem Tehran',
        'Kandovan',
        'Park Jangali',
        'Se-rah-e Kalaleh',
        'Sisangan'
    ])]
    X = data[["tourist per capita", "tourist"]].values
    X = StandardScaler().fit_transform(X)

    # Cluster to 3 clusters
    db = DBSCAN(eps=0.3, min_samples=10).fit(X)
    data["cluster"] = db.labels_

    fig = px.scatter(data, x="tourist", y="tourist per capita", color="cluster", hover_name="city", template='plotly', height=300)
    fig.update_layout(title=f"DBSCAN Clustering of Cities for {year}")
    fig.update_layout(title_font_size=14)
    fig.update_traces(marker=dict(size=8, opacity=0.8))
    fig.update_layout(
        yaxis_type="log"
    )
    st.plotly_chart(fig)

    return data

@st.cache_data
def kmeans(data, year):
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler

    data = data[~data["city"].isin([
        'Ghazvin',
        'Gilan Border',
        'Golestan Forest',
        'Imamzadeh Hashem Tehran',
        'Kandovan',
        'Park Jangali',
        'Se-rah-e Kalaleh',
        'Sisangan'
    ])]
    X = data[["tourist per capita", "tourist"]].values
    X = StandardScaler().fit_transform(X)

    kmeans = KMeans(n_clusters=3, random_state=8).fit(X)
    data["cluster"] = kmeans.labels_

    fig = px.scatter(data, x="tourist", y="tourist per capita", color="cluster", hover_name="city", template='plotly', height=300)
    fig.update_layout(title=f"K-Means Clustering of Cities for {year}")
    fig.update_layout(title_font_size=14)
    fig.update_traces(marker=dict(size=8, opacity=0.8))
    fig.update_layout(
        yaxis_type="log"
    )
    st.plotly_chart(fig)

    return data

@st.cache_data
def gmm(data, year):
    from sklearn.mixture import GaussianMixture
    from sklearn.preprocessing import StandardScaler

    data = data[~data["city"].isin([
        'Ghazvin',
        'Gilan Border',
        'Golestan Forest',
        'Imamzadeh Hashem Tehran',
        'Kandovan',
        'Park Jangali',
        'Se-rah-e Kalaleh',
        'Sisangan'
    ])]
    X = data[["tourist per capita", "tourist"]].values
    X = StandardScaler().fit_transform(X)

    gmm = GaussianMixture(n_components=3, random_state=0).fit(X)
    data["cluster"] = gmm.predict(X)

    # fig = px.scatter(data, x="tourist", y="tourist per capita", color="cluster", hover_name="city", template='plotly') Make it smaller
    fig = px.scatter(data, x="tourist", y="tourist per capita", color="cluster", hover_name="city", template='plotly', height=300)
    fig.update_layout(title=f"GMM Clustering of Cities for {year}")
    fig.update_layout(title_font_size=14)
    fig.update_traces(marker=dict(size=8, opacity=0.8))
    fig.update_layout(
        yaxis_type="log"
    )
    st.plotly_chart(fig)

    return data

def update_query_params():
    date = st.session_state["date"]
    start_date = date[0]
    end_date = date[1]
    st.experimental_set_query_params(start_date=start_date, end_date=end_date)

data = load_data()
coordinates = load_coordinates()
population = load_population()

st.title("Ø´Ù…Ø§Ù„: Ù‚ØµÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†ÙˆØ±ÙˆØ²")
st.write("""
â€«Ø´Ù…Ø§Ù„ Ø§ÛŒØ±Ø§Ù† Ø¨Ø§ Ø·Ø¨ÛŒØ¹Øª Ø¨Ú©Ø± Ø¢Ø¨ Ùˆ Ù‡ÙˆØ§ÛŒ Ø¯Ù„â€ŒÙ¾Ø°ÛŒØ±Ø´ Ù‡Ù…ÙˆØ§Ø±Ù‡ ÛŒÚ©ÛŒ Ø§Ø² Ù…Ù‚Ø§ØµØ¯ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ù…Ø­Ø¨ÙˆØ¨ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª. Ø§Ø² Ø±Ø´Øª ØªØ§ Ù…Ø§Ø²Ù†Ø¯Ø±Ø§Ù†ØŒ Ø§Ø² ØªØ§Ù„Ø´ ØªØ§ Ø¢Ø³ØªØ§Ø±Ø§ØŒ Ù‡Ø± Ù†Ø§Ø­ÛŒÙ‡â€ŒØ§ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù…Ù†Ø·Ù‚Ù‡ Ø¯Ø§Ø±Ø§ÛŒ Ø¬Ø°Ø§Ø¨ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ÛŒ Ø§Ø³Øª Ú©Ù‡ Ù‡Ø± Ø³Ø§Ù„Ù‡ Ú¯Ø±Ø¯Ø´Ú¯Ø±Ø§Ù† Ø¨Ø³ÛŒØ§Ø±ÛŒ Ø±Ø§ Ø¬Ø°Ø¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
""")
st.image("./images/header-image.jpg", use_column_width=True)
st.write("""
Ø¯Ø± Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ØŒ Ù…Ø§ Ù‚ØµØ¯ Ø¯Ø§Ø±ÛŒÙ… Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ÛŒ ØªØ±Ø¯Ø¯ Ø´Ù…Ø§Ø± Ø¨Ù‡  Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ùˆ Ù…Ø¹Ø±ÙÛŒ Ù¾Ø±Ø·Ø±ÙØ¯Ø§Ø±ØªØ±ÛŒÙ† Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ø´Ù…Ø§Ù„ Ø§ÛŒØ±Ø§Ù† Ø¨Ù¾Ø±Ø¯Ø§Ø²ÛŒÙ…. Ø§ÛŒÙ† ØªØ­Ù‚ÛŒÙ‚ Ø¨Ù‡ Ù‡Ø¯Ù Ø§Ø±Ø§Ø¦Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ú©Ø§Ù…Ù„ Ùˆ Ù…ÙÛŒØ¯ Ø¨Ù‡ Ú¯Ø±Ø¯Ø´Ú¯Ø±Ø§Ù† Ùˆ Ø¹Ù„Ø§Ù‚Ù‡â€ŒÙ…Ù†Ø¯Ø§Ù† Ø¨Ù‡ Ø³ÙØ± Ø¯Ø± Ø§ÛŒÙ† Ù…Ù†Ø·Ù‚Ù‡ØŒ Ùˆ Ù‡Ù…Ú†Ù†ÛŒÙ† Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ù…Ù†Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ù‚Ù‚ÛŒÙ† Ùˆ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²Ø§Ù† Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
""")
st.header("""\"Ø¨Ø²Ù† Ø¨Ø±ÛŒÙ… Ø´Ù…Ø§Ù„\"""")
st.write("""â€«Ù‡Ù…Ù‡ Ø³Ø§Ù„Ù‡ Ø§Ø³ØªØ§Ù† Ù‡Ø§ÛŒ Ø´Ù…Ø§Ù„ÛŒ Ú©Ø´ÙˆØ± Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø³ÛŒØ§Ø±ÛŒ Ø§Ø² Ø§ÛŒØ±Ø§Ù†ÛŒØ§Ù† Ø¯Ø± ØªØ¹Ø·ÛŒÙ„Ø§Øª Ø§Ø³Øª Ø§Ù…Ø§ Ø¨Ø¯ÙˆÙ† Ø´Ú©ØŒ Ø¨Ù‡Ø§Ø± Ø´Ù…Ø§Ù„ Ú†ÛŒØ² Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ø³Øª! Ø§ÛŒÙ† ÙØµÙ„ Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ø¢ØºØ§Ø² Ø±ÙˆÙ†Ù‚ Ø·Ø¨ÛŒØ¹ØªØŒ Ø¢Ø¨ Ùˆ Ù‡ÙˆØ§ÛŒ Ù…Ø¹ØªØ¯Ù„ Ùˆ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ø¢ÙØªØ§Ø¨ÛŒØŒ Ø¬Ø°Ø§Ø¨ÛŒØª Ø®Ø§ØµÛŒ Ø¨Ù‡ Ø³ÙØ±Ù‡Ø§ Ø¯Ø± Ø§ÛŒÙ† Ù…Ù†Ø§Ø·Ù‚ Ù…ÛŒâ€ŒØ¨Ø®Ø´Ø¯. ØªØ¹Ø·ÛŒÙ„Ø§Øª Ù†ÙˆØ±ÙˆØ² Ù†ÛŒØ² Ø¨Ù‡Ø§Ù†Ù‡â€ŒØ§ÛŒ Ø¹Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ±Ø§Ø± Ø§Ø² Ø±ÙˆØ²Ù…Ø±Ú¯ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø®ØªÙ† Ø¨Ù‡ Ø³ÙØ±Ù‡Ø§ÛŒ Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ø§Ø³Øª 
""")

cities_chart(data, ['Rasht', 'Sari', 'Gorgan'], 'Incoming Cars and Buses for Province Centers')
st.write("""
Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ ØªØ¹Ø¯Ø§Ø¯ ØªØ±Ø¯Ø¯Ù‡Ø§ Ú©Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ø¯Ø¯ Ø´Ù…Ø§Ø± Ø¯Ø± Ø§Ø®ØªÛŒØ§Ø± Ù…Ø§ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª ØŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ú©Ù‡ Ø´Ù…Ø§Ù„ Ú©Ø´ÙˆØ± Ø­ØªÛŒ Ø¯Ø± Ø¯ÙˆØ±Ø§Ù† Ú©Ø±ÙˆÙ†Ø§ Ù…Ø­Ø¨ÙˆØ¨ÛŒØª Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ù…Ù‚ØµØ¯ Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ø®Ø³ØªÚ¯ÛŒ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø­ÙØ¸ Ú©Ø±Ø¯Ù‡ Ø§Ø³Øª.
Ù‡Ù…Ú†Ù†ÛŒÙ† Ù¾Ø³ Ø§Ø² Ú¯Ø°Ø´Øª Ø¯ÙˆØ±Ø§Ù† Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø§Ø¹Ù…Ø§Ù„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ù†ØªØ±Ù„ Ø´ÛŒÙˆØ¹ Ú©Ø±ÙˆÙ†Ø§ ØŒ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒ Ø±Ø³Ø¯ Ú©Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¨Ù‡ Ø³Ù…Øª Ø²Ù†Ø¯Ú¯ÛŒ Ù¾ÛŒØ´ Ø§Ø² Ú©Ø±ÙˆÙ†Ø§ Ø¨Ø±Ú¯Ø´ØªÙ‡ Ø§Ø³Øª.
""")

st.write("""
Ø´Ø§ÛŒØ¯ ÙÚ©Ø± Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø´Ù‡Ø± Ù‡Ø§ÛŒ Ø¨Ø§ Ø¬Ù…Ø¹ÛŒØª ØªÙ‚Ø±ÛŒØ¨Ø§ ÛŒÚ©Ø³Ø§Ù† ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´Ø§Ø¨Ù‡ÛŒ Ø§Ø² Ù…Ø³Ø§ÙØ±Øª Ù†ÙˆØ±ÙˆØ²ÛŒ  Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯.Ø§Ú¯Ø±Ø¨Ø§ÙˆØ± Ø´Ù…Ø§ Ú†Ù†ÛŒÙ† Ø§Ø³Øª Ø¨Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø± Ø²ÛŒØ± ØªÙˆØ¬Ù‡ Ú©Ù†ÛŒØ¯:
""")

cities_chart(data, ['Astaneh', 'Asalem', 'Kiyakala'], 'Incoming Cars and Buses for Cities with Similar Population')

st.write("""
Ø´Ù‡Ø±â€ŒÙ‡Ø§ÛŒ Ø¢Ø³ØªØ§Ù†Ù‡ ØŒ Ú©ÛŒØ§Ú©Ù„Ø§ Ùˆ Ø§Ø³Ø§Ù„Ù… Ø¨Ù‡ ØªØ±ØªÛŒØ¨ Ø¨Ø§ Ø¬Ù…Ø¹ÛŒØª 7166 Ùˆ 8140 Ùˆ 10720 ØªÙˆØ²ÛŒØ¹ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ  ÛŒÚ©Ø³Ø§Ù†ÛŒ Ù†Ø¯Ø§Ø´ØªÙ‡ Ùˆ Ù…Ø«Ø§Ù„ Ù†Ù‚Ø¶ÛŒ Ø¨Ø± Ø§ÛŒÙ† Ø¨Ø§ÙˆØ±Ù‡Ø³ØªÙ†Ø¯
Ùˆ Ù†Ø´Ø§Ù† Ù…ÛŒ Ø¯Ù‡Ù†Ø¯ Ù…Ø³Ø§ÙØ±Ø§Ù† Ù…Ù‚ØµØ¯ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø§ Ù…Ø¹ÛŒØ§Ø±
Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ùˆ Ø¨Ù‡ ØµÙˆØ±Øª Ù‡ÙˆØ´Ù…Ù†Ø¯Ø§Ù†Ù‡ ØªØ±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒ Ú©Ù†Ù†Ø¯.

Ø¯Ø± Ø§Ø¯Ø§Ù…Ù‡ØŒ Ù…Ø§ Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ùˆ Ù…Ø¹Ø±ÙÛŒ Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ø§Ø² Ø´Ù…Ø§Ù„ Ú©Ø´ÙˆØ± Ù‡Ø³ØªÛŒÙ… Ú©Ù‡ Ø¯Ø± Ø³Ù‡ Ø³Ø§Ù„ Ú¯Ø°Ø´ØªÙ‡ Ø§Ø² Ù…Ø­Ø¨ÙˆØ¨ÛŒØª Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø± Ù…ÛŒØ§Ù† Ù…Ø³Ø§ÙØ±Ø§Ù†  Ù†ÙˆØ±ÙˆØ²ÛŒ Ø¨Ø±Ø®ÙˆØ±Ø¯Ø§Ø± Ø¨ÙˆØ¯Ù‡â€ŒØ§Ù†Ø¯ØŒ Ùˆ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…. Ø³Ù¾Ø³ØŒ Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù†Ø§Ø·Ù‚ÛŒ Ù…ÛŒâ€ŒÙ¾Ø±Ø¯Ø§Ø²ÛŒÙ… Ú©Ù‡ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ù…Ù†Ø§Ø³Ø¨ÛŒ Ø¯Ø§Ø±Ù†Ø¯ Ùˆ Ø´Ø§Ù‡Ø¯ ØªÙˆØ³Ø¹Ù‡ Ùˆ Ø±Ø´Ø¯ Ø§ÛŒÙ† ØµÙ†Ø¹Øª Ø¯Ø± Ø§ÛŒÙ† Ù†ÙˆØ§Ø­ÛŒ Ù‡Ø³ØªÛŒÙ…. 
â€«
""")

st.header("Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ")
st.write("""
Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø±ÛŒ Ù…Ø§Ù†Ù†Ø¯ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (clustering) Ùˆ ØªØ³Øª ÙØ±Ø¶ÛŒÙ‡ (hypothesis testing) Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¯Ø±Ú© Ø¹Ù…ÛŒÙ‚â€ŒØªØ±ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ ØªØ±Ø¬ÛŒØ­Ø§Øª Ù…Ø³Ø§ÙØ±Ø§Ù† Ø¨Ù‡ Ù…Ø§ Ø¨Ø¯Ù‡Ø¯. Ø¯Ø± Ø§Ø¯Ø§Ù…Ù‡ØŒ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ø®Ù„Ø§ØµÙ‡ ØªÙˆØ¶ÛŒØ­ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…:
""")
st.subheader("Ø±ÙˆØ´ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ (Clustering)")
st.write("""
Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÛŒÚ©ÛŒ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ù‡Ø¯Ù Ø¢Ù† Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø¨Ø§Ù‡Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÛŒØ§Ù† Ø¢Ù†â€ŒÙ‡Ø§ Ø§Ø³Øª. Ø¯Ø± Ù…ÙˆØ±Ø¯ ØªØ­Ù„ÛŒÙ„ Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ø´Ù…Ø§Ù„ Ø§ÛŒØ±Ø§Ù†ØŒ Ù…Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø§Ø² Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ù‡Ø±Ù‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ ØªØ¹Ø¯Ø§Ø¯ Ú¯Ø±Ø¯Ø´Ú¯Ø±Ø§Ù†ØŒ Ù†Ø³Ø¨Øª Ú¯Ø±Ø¯Ø´Ú¯Ø± Ø¨Ù‡ Ø¬Ù…Ø¹ÛŒØª Ùˆ Ù†Ø±Ø® ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ø´Ù‡Ø±Ù‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…. Ø§ÛŒÙ† ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ Ø¨Ù‡ Ù…Ø§ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø´Ù‡Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ÛŒ Ø¯Ø± Ø¬Ø°Ø¨ Ú¯Ø±Ø¯Ø´Ú¯Ø± Ø¯Ø§Ø±Ù†Ø¯ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒÙ….
""")

st.subheader("ØªØ³Øª ÙØ±Ø¶ (Hypothesis Testing)")
st.write("""
ØªØ³Øª ÙØ±Ø¶ ÛŒÚ© Ø±ÙˆØ´ Ø¢Ù…Ø§Ø±ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ØµØ­Øª ÛŒÚ© ÙØ±Ø¶ÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø¨Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„ØŒ Ø§Ú¯Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒÙ… Ø¨Ø¯Ø§Ù†ÛŒÙ… Ø¢ÛŒØ§ ØªÙØ§ÙˆØª Ù…Ø¹Ù†ÛŒâ€ŒØ¯Ø§Ø±ÛŒ Ø¨ÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ú¯Ø±Ø¯Ø´Ú¯Ø±Ø§Ù† Ø¯Ø± Ø¯Ùˆ Ø´Ù‡Ø± Ø®Ø§Øµ Ø¯Ø± Ø´Ù…Ø§Ù„ Ø§ÛŒØ±Ø§Ù† ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ø®ÛŒØ±ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø§Ø² ØªØ³Øª ÙØ±Ø¶ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…. Ø§ÛŒÙ† Ø±ÙˆØ´ Ø¨Ù‡ Ù…Ø§ Ø§Ù…Ú©Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ ØªØ§ Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø¨ÛŒØ´ØªØ±ÛŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ú©Ù†ÛŒÙ… Ùˆ Ù…Ø´Ø®Øµ Ú©Ù†ÛŒÙ… Ú©Ù‡ Ø¢ÛŒØ§ ØªÙØ§ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡â€ŒØ´Ø¯Ù‡ ØªØµØ§Ø¯ÙÛŒ Ù‡Ø³ØªÙ†Ø¯ ÛŒØ§ Ù†Ø§Ø´ÛŒ Ø§Ø² Ø¹ÙˆØ§Ù…Ù„ Ø¨Ù†ÛŒØ§Ø¯ÛŒÙ† Ø¯Ø± Ø¬Ø°Ø¨ Ú¯Ø±Ø¯Ø´Ú¯Ø±Ø§Ù†.
""")

st.subheader("Ù†Ø³Ø¨Øª ØªÙˆØ±ÛŒØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù")
st.write("""
Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…Ø­ÛŒØ·ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ø´Ù†Ø§ÛŒÛŒ Ø¨ÛŒØ´ØªØ± Ø´Ù…Ø§ ØªØ¹Ø¨ÛŒÙ‡ Ø´Ù…Ø§ Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ø§ Ù…Ø´Ø®Øµâ€ŒÚ©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ® Ù…Ø¯Ù†Ø¸Ø± Ø®ÙˆØ¯ØŒ ØªØ¹Ø¯Ø§Ø¯ Ø³ÙˆØ§Ø±ÛŒ Ùˆ Ù…ÛŒÙ†ÛŒâ€ŒØ¨ÙˆØ³â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒØŒ Ø®Ø±ÙˆØ¬ÛŒ Ùˆ ØªØ¹Ø¯Ø§Ø¯ Ø§ØªÙˆÙ…Ø¨ÛŒÙ„â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù…ÛŒâ€ŒØ±ÙˆØ¯ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú¯Ø±Ø¯Ø´Ú¯Ø±Ø§Ù† Ø¨Ø§Ø´Ø¯ (Ú†Ø±Ø§ Ú©Ù‡ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ø±ÙˆØ² Ø¯Ø± Ø´Ù‡Ø± ØªÙˆÙ‚Ù Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯) Ø±Ø§ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ù†ÛŒØ¯.
""")
start_date, end_date = st.select_slider(
    'Select the date range for analysis.',
    options=find_dates(),
    key='date',
    value=("1400-12-25", "1401-1-18"),
    on_change=update_query_params
)

city_data = city_input(data, start_date, end_date)
st.dataframe(city_data, width=1000)

mazandaran = [36.5700, 51.900]
zoom_level = 6.5

map(city_data.merge(coordinates, on="city", how="left")[["lat", "lon", "net", "tourist"]], mazandaran[0], mazandaran[1], zoom_level)

st.header("""Ø§Ù†ÙˆØ§Ø¹ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ""")
st.write("""
ØªØ§ Ú©Ù†ÙˆÙ† Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø³Ø¦Ù„Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª Ú©Ù‡ Ø§Ø² Ù„Ø­Ø§Ø¸ Ù…Ø¹ÛŒØ§Ø± ØªØ´Ø®ÛŒØµ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ùˆ Ù†Ø­ÙˆÙ‡â€ŒÛŒ Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© Ø®ÙˆØ´Ù‡ØŒ Ø¨Ø§ ÛŒÚ©â€ŒØ¯ÛŒÚ¯Ø± ØªÙØ§ÙˆØª Ø¨Ø³ÛŒØ§Ø±ÛŒ Ø¯Ø§Ø±Ù†Ø¯. Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„â€ŒØ¨ÙˆØ¯Ù† Ø¨Ø±Ø±Ø³ÛŒ Ø®ÙˆØ¯ Ø§Ø² Ø³Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ú©Ù‡ Ø§Ø³Ø§Ø³ Ù…ØªÙØ§ÙˆØªÛŒ Ø¯Ø± Ú©Ø§Ø±Ú©Ø±Ø¯ Ø¯Ø§Ø±Ù†Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒÙ…. Ø§ÛŒÙ† Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ Ø¹Ø¨Ø§Ø±ØªÙ†Ø¯ Ø§Ø²:
""")
st.subheader("""Ù…Ø¯Ù„â€Œ Ù…Ø±Ú©Ø² Ú¯Ø±Ø§""")
st.write("""
Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ´ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø³ØªÙ‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ Ù‡Ù… ÛŒÚ© Ù…Ø±Ú©Ø² ØªØ¹ÛŒÛŒÙ† Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù†Ù‚Ø·Ù‡â€ŒØ§ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø®ØµÙˆØµÛŒØ§Øª Ø§ØµÙ„ÛŒ Ø¯Ø³ØªÙ‡ Ø±Ø§ Ø¯Ø§Ø±Ø¯ØŒ Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ù‡Ø± Ú†Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§ Ø§Ø² Ø§ÛŒÙ† Ù…Ø±Ú©Ø² Ø¯ÙˆØ±ØªØ± Ø´ÙˆÙ†Ø¯ØŒ Ø¨Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ú©Ù…ØªØ±ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯. Ø±ÙˆØ´ k Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†  (k-means) Ù¾Ø±Ú©Ø§Ø±Ø¨Ø±Ø¯ØªØ±ÛŒÙ† Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡ Ø§Ø³Øª Ú©Ù‡ Ù†Ù‚Ø§Ø· Ù…Ø±Ú©Ø² Ù‡Ø± Ø®ÙˆØ´Ù‡ Ø±Ø§ Ø¨Ø±Ø§Ø³Ø§Ø³ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ú¯Ø±ÙØªÙ† Ø§Ø² Ø§Ø¹Ø¶Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± Ù‡Ø± Ù…Ø±Ø­Ù„Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯ Ù…Ø´Ø®Øµ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…Ø±Ú©Ø² Ø¯Ø³ØªÙ‡ Ù†ØªÛŒØ¬Ù‡ ÛŒÚ© Ø´ÙˆØ±Ø§ Ø¨ÛŒÙ† Ø§Ø¹Ø¶Ø§ÛŒ ÙØ¹Ù„ÛŒ Ø¯Ø³ØªÙ‡ Ø§Ø³Øª.
Ø¯Ø± Ø²ÛŒØ± Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù†ØªØ§ÛŒØ¬ Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ù¾Ø±Ú¯Ø±Ø¯Ø´Ú¯Ø± Ø±Ø§ Ú©Ù‡ Ø§Ø² Ø§ÛŒÙ† Ø±ÙˆØ´ Ø¨Ù‡ Ø¯Ø³Øª Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ù†ÛŒØ¯.
""")

first_city_population = aggregate_data(city_input(data, "1399-12-25", "1400-1-18"))
first_kmeans = kmeans(first_city_population, '1400')[["city", "cluster", "tourist", "tourist per capita"]]
second_city_population = aggregate_data(city_input(data, "1400-12-25", "1401-1-18"))
second_kmeans = kmeans(second_city_population, '1401')[["city", "cluster"]]
third_city_population = aggregate_data(city_input(data, "1401-12-25", "1402-1-18"))
third_kmeans = kmeans(third_city_population, '1402')[["city", "cluster"]]
st.write("""
Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ Ú©Ù‡ Ø¯Ø± Ù‡Ø± Ø³Ø§Ù„ Ù…Ø§ Ø¯Ùˆ Ø¯Ø³ØªÙ‡ Ø´Ù‡Ø± Ø¯Ø§Ø±ÛŒÙ… Ú©Ù‡ Ø¯Ø± Ø¨Ø§Ù„Ø§ Ùˆ Ø³Ù…Øª Ø±Ø§Ø³Øª Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ø² Ø§ÛŒÙ† Ø´Ù‡Ø±Ù‡Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ù†Ø§Ù… Ø¨Ø±Ø¯. Ø¯Ø³ØªÙ‡ Ø³Ù…Øª Ø±Ø§Ø³Øª Ø´Ù‡Ø±Ù‡Ø§ÛŒÛŒ Ø§Ø³Øª Ú©Ù‡ Ù¾Ø°ÛŒØ±Ø§ÛŒ Ú¯Ø±Ø¯Ø´Ú¯Ø±Ø§Ù† Ø¨Ø³ÛŒØ§Ø±ÛŒ Ø¨ÙˆØ¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ø¹Ù…ÙˆÙ…Ø§ Ø´Ø§Ù…Ù„ Ø´Ù‡Ø±Ù‡Ø§ÛŒÛŒ Ù†Ø§Ù…â€ŒØ¢Ø´Ù†Ø§Ø³Øª. Ø¯Ø³ØªÙ‡ Ø¨Ø§Ù„Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ú©Ù…ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡â€ŒØ´Ø¯Ù‡ ØªØ± Ù‡Ø³ØªÙ†Ø¯. Ø§Ú¯Ø±Ú†Ù‡ Ø§ÛŒÙ† Ø´Ù‡Ø±Ù‡Ø§ Ø¯Ø± Ù†Ø±Ø® Ú¯Ø±Ø¯Ø´Ú¯Ø± Ù…Ù‚Ø¯Ø§Ø± Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±ÛŒ Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯ØŒ Ø§Ù…Ø§ ØªØ¹Ø¯Ø§Ø¯ Ú¯Ø±Ø¯Ø´Ú¯Ø± Ø¨Ù‡ Ø§Ø²Ø§ÛŒ Ø¬Ù…Ø¹ÛŒØª Ø¢Ù†â€ŒÙ‡Ø§ Ù…Ù‚Ø¯Ø§Ø± Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø§Ø³Øª.
""")
# Find cities that are in the same cluster for all three years and show them in a dataframe along their clusters
first_kmeans.columns = ["city", "1400 cluster", "tourist", "tourist per capita"]
second_kmeans.columns = ["city", "1401 cluster"]
third_kmeans.columns = ["city", "1402 cluster"]
kmeans_clusters = first_kmeans.merge(second_kmeans, on="city", how="inner").merge(third_kmeans, on="city", how="inner")
# Keep only cities that are in the same cluster for all three years
kmeans_clusters = kmeans_clusters[((kmeans_clusters["1400 cluster"] == 1) & (kmeans_clusters["1401 cluster"] == 2) & (kmeans_clusters["1402 cluster"] == 2)) | ((kmeans_clusters["1400 cluster"] == 2) & (kmeans_clusters["1401 cluster"] == 1) & (kmeans_clusters["1402 cluster"] == 1))]
kmeans_clusters = kmeans_clusters[kmeans_clusters["1401 cluster"] != 0]
kmeans_clusters = kmeans_clusters[kmeans_clusters["1402 cluster"] != 0]
# Drop 1400 cluster and 1401 cluster
kmeans_clusters.drop(columns=["1400 cluster", "1401 cluster"], inplace=True)
kmeans_clusters.columns = ["City", "Tourist", "Tourist Per Capita", "City Type"]
# Change 1 value in City Type to Most Popular
kmeans_clusters.loc[kmeans_clusters["City Type"] == 1, "City Type"] = "Based on Popularity"
kmeans_clusters.loc[kmeans_clusters["City Type"] == 2, "City Type"] = "Based on Tourist Per Capita"
st.dataframe(kmeans_clusters, width=1000)

st.subheader("Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± ØªØ±Ø§Ú©Ù…")
st.write("""
â€«Ø¯Ø± Ø§ÛŒÙ† Ù…Ø¯Ù„ØŒ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ù…ØªÙ†Ø§Ø³Ø¨ Ø¨Ø§ Ù†Ø§Ø­ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù…ØªØ±Ø§Ú©Ù… Ù†Ù‚Ø§Ø· Ø¯Ø± Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯.
â€«
""")
first_dbscan = dbscan(first_city_population, '1400')[["city", "cluster", "tourist", "tourist per capita"]]
second_dbscan = dbscan(second_city_population, '1401')[["city", "cluster"]]
third_dbscan = dbscan(third_city_population, '1402')[["city", "cluster"]]

first_dbscan.columns = ["city", "1400 cluster", "tourist", "tourist per capita"]
second_dbscan.columns = ["city", "1401 cluster"]
third_dbscan.columns = ["city", "1402 cluster"]

dbscan_clusters = first_dbscan.merge(second_dbscan, on="city", how="inner").merge(third_dbscan, on="city", how="inner")
dbscan_clusters = dbscan_clusters[dbscan_clusters["1400 cluster"] == dbscan_clusters["1401 cluster"]]
dbscan_clusters = dbscan_clusters[dbscan_clusters["1401 cluster"] == dbscan_clusters["1402 cluster"]]
dbscan_clusters = dbscan_clusters[dbscan_clusters["1401 cluster"] != 0]
dbscan_clusters.drop(columns=["1400 cluster", "1401 cluster", "1402 cluster"], inplace=True)
dbscan_clusters.columns = ["City", "Tourist", "Tourist Per Capita"]
st.dataframe(dbscan_clusters, width=1000)

st.subheader("Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± ØªÙˆØ²ÛŒØ¹ Ù†Ù‚Ø§Ø·")
st.write("""
Ø¯Ø± Ø§ÛŒÙ† Ù…Ø¯Ù„ØŒ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ Ø¨Ø§ ÙØ±Ø¶ Ù¾ÛŒØ±ÙˆÛŒ Ø§Ø² ÛŒÚ© ØªÙˆØ²ÛŒØ¹ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ù…Ø´Ø®Øµ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
Ø§Ø² Ø¬Ù…Ù„Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ø±ÙˆÙ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ù…Ø¯Ù„ØŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø¨ÛŒØ´ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ù…ÛŒØ¯ Ø±ÛŒØ§Ø¶ÛŒ Ø§Ø³Øª.
""")
first_gmm = gmm(first_city_population, '1400')[["city", "cluster", "tourist", "tourist per capita"]]
second_gmm = gmm(second_city_population, '1401')[["city", "cluster"]]
third_gmm = gmm(third_city_population, '1402')[["city", "cluster"]]

first_gmm.columns = ["city", "1400 cluster", "tourist", "tourist per capita"]
second_gmm.columns = ["city", "1401 cluster"]
third_gmm.columns = ["city", "1402 cluster"]

gmm_clusters = first_gmm.merge(second_gmm, on="city", how="inner").merge(third_gmm, on="city", how="inner")
gmm_clusters = gmm_clusters[gmm_clusters["1400 cluster"] == gmm_clusters["1401 cluster"]]
gmm_clusters = gmm_clusters[gmm_clusters["1401 cluster"] == gmm_clusters["1402 cluster"]]
gmm_clusters = gmm_clusters[gmm_clusters["1401 cluster"] != 0]

gmm_clusters.drop(columns=["1400 cluster", "1401 cluster", "1402 cluster"], inplace=True)
gmm_clusters.columns = ["City", "Tourist", "Tourist Per Capita"]
st.dataframe(gmm_clusters, width=1000)

st.header("ØªØ³Øª ÙØ±Ø¶")
st.markdown("""
Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø§Ø² Ø´Ù‡Ø±Ù‡Ø§ÛŒ ÙˆØ§Ø³Ø·Ù‡ Ú©Ù‡ Ù…Ø­Ù„ Ø§Ø³ØªØ±Ø§Ø­Øª ÛŒØ§ Ú¯Ø°Ø± Ú¯Ø±Ø¯Ø´Ú¯Ø±Ø§Ù† Ù‡Ø³ØªÙ†Ø¯ØŒ Ø´Ø§Ø®Øµ Ù…ÛŒØ²Ø§Ù† Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø±Ø§ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Ø§Ø³ ØªØ¹Ø±ÛŒÙ Ú©Ø±Ø¯ÛŒÙ…:

- \(X_{i}\): ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ù‡ Ù‡Ø± Ø´Ù‡Ø±
  Ø§ÛŒÙ† Ù…ØªØºÛŒØ± Ø¨Ø± Ø§Ø³Ø§Ø³ ØªÙØ§ÙˆØª ØªØ¹Ø¯Ø§Ø¯ ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ø®ÙˆØ¯Ø±ÙˆÙ‡Ø§ Ø¨ÙˆØ¯Ù‡ Ú©Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ù…Ù†ÙÛŒ Ø¨ÙˆØ¯Ù† Ø§ÛŒÙ† ØªÙØ§ÙˆØªØŒ Ø¢Ù† Ø±Ø§ ØµÙØ± Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡â€ŒØ§ÛŒÙ….
- \(P\): Ø¬Ù…Ø¹ÛŒØª Ù‡Ø± Ø´Ù‡Ø± Ú©Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±Ø´Ù…Ø§Ø±ÛŒ 1395 Ùˆ Ø¨Ø±Ø§ÛŒ Ø¨Ø¹Ø¶ÛŒ Ø´Ù‡Ø±Ù‡Ø§ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ 1385 Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.

- \(\mu = 3.2\%\) 
- \(n\): Ø¨Ø§Ø²Ù‡ ØªØ¹Ø·ÛŒÙ„Ø§Øª Ø¯Ø± Ù‡Ø± Ø³Ø§Ù„

Ø¨Ù‡ Ø§Ø²Ø§ÛŒ Ù‡Ø± Ø´Ù‡Ø± ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ \(n\) ØªØ§ÛŒÛŒ Ø§Ø² ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ù‡ Ø¢Ù† Ø¯Ø± ÛŒÚ© Ø³Ø§Ù„ Ù…Ø´Ø®Øµ ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.
Ø§Ø¯Ø¹Ø§ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø´Ù‡Ø±ÛŒ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø§Ø³Øª Ú©Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ú¯Ø±Ø¯Ø´Ú¯Ø±Ø§Ù† Ø¢Ù† Ø¨Ù‡ Ø¬Ù…Ø¹ÛŒØªØ´ Ø­Ø¯Ø§Ù‚Ù„ \(3.2\%\) Ø¨Ø§Ø´Ø¯.
Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø´Ù‡Ø± Ø¯Ø± Ù‡Ø± Ø³Ø§Ù„ Ø§ÛŒÙ† Ø¢Ø²Ù…ÙˆÙ† Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¬Ø¯ÙˆÙ„ \(t\)-student Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡ Ùˆ Ø¯Ø± Ù†Ù‡Ø§ÛŒØª Ø¨Ù‡ Ø§Ø²Ø§ÛŒ Ù‡Ø± Ø´Ù‡Ø± Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ Ø§ÛŒÙ† Ù…Ø¹ÛŒØ§Ø± Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ù‡Ø³ØªÙ†Ø¯ Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒÙ….

**ÙØ±Ø¶ÛŒÙ‡â€ŒÙ‡Ø§**:
- \(H_0\): Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† \(\leq 0.032\)
- \(H_1\): Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† \(> 0.032\)

Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ 
\[
\frac{\bar{X} - \mu}{\frac{s}{\sqrt{n}}} < t_{(1-\alpha)}(n -1 )
\]
Ø¨Ø§Ø´Ø¯ ÙØ±Ø¶ ØµÙØ± Ø±Ø¯ Ø´Ø¯Ù‡ Ùˆ Ø´Ù‡Ø± Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø§Ø³Øª.

Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† Ø¨Ø±ØªØ±ÛŒÙ† Ø´Ù‡Ø±Ù‡Ø§ Ø¯Ø± Ø§ÛŒÙ† Ø³Ù‡ Ø³Ø§Ù„ØŒ Ø§Ø² Ù‡Ø± Ø³Ø§Ù„ 10 Ø´Ù‡Ø± Ø¨Ø±ØªØ± Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ùˆ Ø´Ù‡Ø±Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù¾Ø±ØªÙ‚Ø§Ø¶Ø§ØªØ±ÛŒÙ† Ø´Ù‡Ø±Ù‡Ø§ Ù…Ø¹Ø±ÙÛŒ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ú©Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø¢Ù†â€ŒÙ‡Ø§ Ø¯Ø± Ø§ÛŒÙ† Ø³Ù‡ Ø³Ø§Ù„ Ø¨ÛŒØ´ÛŒÙ†Ù‡ Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª.

**Ù†Ø­ÙˆÙ‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ \(\mu\)**: 
Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù†Ø³Ø¨Øª Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø¨Ù‡ Ø¬Ù…Ø¹ÛŒØª Ø¨Ø±Ø§ÛŒ Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ÛŒ 100000 Ù†ÙØ± Ø¯Ø± Ø·ÛŒ Ø³Ù‡ Ø³Ø§Ù„ Ù…ØªÙˆØ§Ù„ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¢Ù†â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø§ÛŒÙ† Ù…Ø¹ÛŒØ§Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ù„Ø³ØªØ§Ù† 1402 ØªÙˆØ³Ø· Ø³Ø§Ù…Ø§Ù†Ù‡ Ø«Ø¨Øª Ù†Ø´Ø¯Ù‡ Ø§Ø³ØªØ› Ù„Ø°Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„ ØªØ®Ù…ÛŒÙ† Ù…Ù†Ø§Ø³Ø¨ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡ Ø¨ÙˆØ¯ÛŒÙ… Ø§Ù…Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ø§ØµÙ„ Ù†ØªØ§ÛŒØ¬ Ø¯Ø±Ø³ØªÛŒ Ù†Ø¯Ø§Ø´ØªÙ†Ø¯. Ù„Ø°Ø§ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ù‡ ØµÙˆØ±Øª Ø±ÙˆØ²Ø§Ù†Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ 1400 Ùˆ 1401 Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø´Ù‡Ø± Ú¯Ù„Ø³ØªØ§Ù† Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø´Ø¯Ù‡ Ø§Ø³Øª.
""")
hypothesis_test = load_test()
st.dataframe(hypothesis_test, width=1000)

st.header("Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ")
st.write("""
Ø¨Ø±Ø§Ø³Ø§Ø³ Ø¢Ù†Ú†Ù‡ Ø§Ø² Ø¢Ø²Ù…Ø§ÛŒØ´ Ø¨Ø§ Ú†Ù‡Ø§Ø± Ø±ÙˆØ´ Ú¯ÙØªÙ‡ Ø´Ø¯Ù‡ Ø¯Ø± Ø¨Ø§Ù„Ø§ Ø¨Ù‡ Ø¯Ø³Øª Ø¢Ù…Ø¯ØŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ Ù…Ø¯Ù„ Ù…Ø±Ú©Ø²â€Œ Ú¯Ø±Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù†ØªÛŒØ¬Ù‡ Ø±Ø§ Ø¨Ù‡ Ù„Ø­Ø§Ø¸ ØªÙØ³ÛŒØ± Ø¯Ø± Ø§Ø®ØªÛŒØ§Ø± Ù…Ø§ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒØ¯Ù‡Ø¯. Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Ø§Ø³ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø´Ù‡Ø±Ù‡Ø§ Ø±Ø§ Ø¨Ù‡ Ø¯Ùˆ Ø¯Ø³ØªÙ‡ ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ø±Ø¯ Ú©Ù‡ Ø¯Ø³ØªÙ‡ Ø§ÙˆÙ„ØŒ Ø¨Ø³ÛŒØ§Ø± Ú¯Ø±Ø¯Ø´Ú¯Ø±Ù¾Ø°ÛŒØ± Ù‡Ø³Øª Ø¢Ù…Ø§Ø± ØªÙˆØ±ÛŒØ³Øª Ø¨Ø§Ù„Ø§ÛŒÛŒ Ø±Ø§ Ø¨Ù‡ Ø®ÙˆØ¯ Ø§Ø®ØªØµØ§Øµ Ø¯Ø§Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ø¯Ø³ØªÙ‡ Ø¯ÙˆÙ… Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø±Ø´Ø¯ Ø¯Ø§Ø±Ù†Ø¯. Ø§ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø¨Ø³ÛŒØ§Ø± Ø²ÛŒØ§Ø¯ Ú¯Ø±Ø¯Ø´Ú¯Ø±Ø§Ù† Ø§Ø² Ø§ÛŒÙ† Ø´Ù‡Ø±Ù‡Ø§ Ø¯Ø± Ø§ÛŒØ§Ù… ØªØ¹Ø·ÛŒÙ„Ø§Øª Ù†ÙˆØ±ÙˆØ² Ø¨ÙˆØ¯Ù‡ Ø§Ø³Øª Ø¨Ù‡ Ø·ÙˆØ±ÛŒ Ú©Ù‡ Ø¯Ø± Ø³ÛŒØ§Ù‡â€ŒØ¨ÛŒØ´ØªÙ‡ Ù…Ø§ Ø¨Ù‡ Ø§Ø²Ø§ÛŒ Ù‡Ø± Ù†ÙØ± Ø§Ø² Ø¬Ù…Ø¹ÛŒØª Ø´Ù‡Ø± Û±Û²Û°Û° Ø®ÙˆØ¯Ø±ÙˆÛŒ ØªÙˆØ±ÛŒØ³Øª Ø¯Ø§Ø´ØªÙ‡â€ŒØ§ÛŒÙ….
""")
st.write("""
Ø­Ø§Ù„ Ø¯Ø± Ù¾Ø§ÛŒÛŒÙ† Ø´Ù‡Ø± Ø¯ÙˆØ¢Ø¨ Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² Ø§ÛŒÙ† Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ø¨Ø§ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø¨Ø§Ù„Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø±Ø¯Ù‡ Ùˆ Ø§Ø¨Ø¹Ø§Ø¯ Ù…Ø®ØªÙ„Ù Ø¢Ù† Ø±Ø§ Ø´Ø±Ø­ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…:
""")
st.subheader("Ø¯ÙˆØ¢Ø¨ Ú©Ø¬Ø§Ø³Øª")
st.write("""
Ø§Ø² Ù…Ø­ÙˆØ± Ú©Ø±Ø¬ Ù€ Ú†Ø§Ù„ÙˆØ³ Ú©Ù‡ Ø¨Ù‡ Ø³Ù…Øª Ú†Ø§Ù„ÙˆØ³ Ø­Ø±Ú©Øª Ú©Ù†ÛŒØ¯ 7 Ú©ÛŒÙ„ÙˆÙ…ØªØ± Ø¨Ø¹Ø¯ Ø§Ø² Ù…Ø±Ø²Ù†â€ŒØ¢Ø¨Ø§Ø¯ Ø¨Ù‡ Ø¯ÙˆØ±Ø§Ù‡Ù‰ Ú©Ø¬ÙˆØ± Ù…Ù‰â€ŒØ±Ø³ÛŒØ¯. Ø¯Ø± Ú†Ù†Ø¯ Ú©ÛŒÙ„ÙˆÙ…ØªØ±ÛŒ Ø¢Ù† Ø¨Ù‡ Ø³Ù…Øª Ú†Ø§Ù„ÙˆØ³ØŒ Ø¨Ù‡ ÛŒÚ© Ø³Ù‡ Ø±Ø§Ù‡ÛŒ Ù…ÛŒâ€ŒØ±Ø³ÛŒØ¯ Ú©Ù‡ Â«â€ŒØ¯Ùˆ Ø¢Ø¨ Ú©Ø¬ÙˆØ±Â» â€ŒÙ†Ø§Ù… Ø¯Ø§Ø±Ø¯â€Œ. Ø§Ú¯Ø± Ø§Ø² Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù‡ Ø³Ù…Øª Ø±Ø§Ø³Øª Ø­Ø±Ú©Øª Ú©Ù†ÛŒØ¯ØŒ ÙˆØ§Ø±Ø¯ Ø¬Ø§Ø¯Ù‡ Â«Ø¯Ø´Øª Ù†Ø¸ÛŒØ±Â» Ù…ÛŒâ€ŒØ´ÙˆÛŒØ¯ 
Ø§ÙˆØ§ÛŒÙ„ Ø¬Ø§Ø¯Ù‡ Ù¾ÙˆØ´ÛŒØ¯Ù‡ Ø§Ø² Ø¨Ø§Øº Ù‡Ø§ÛŒÛŒ Ø§Ø³Øª Ú©Ù‡ Ø§Ø² Ø³ÛŒ Ú†Ù‡Ù„ Ø³Ø§Ù„ Ù¾ÛŒØ´ Ø§Ø­Ø¯Ø§Ø« Ø´Ø¯Ù‡ Ùˆ Ø¯Ø± Ú©Ù†Ø§Ø± Ø¬Ù†Ú¯Ù„ Ø¯Ø³Øª Ú©Ø§Ø´Øª Ú©Ø§Ø¬ Ùˆ Ø³Ø±ÙˆØŒ Ø³Ø±Ø³Ø¨Ø²ÛŒ Ùˆ Ø·Ø±Ø§ÙˆØªÛŒ Ø¨Ù‡ Ø¯Ø´Øª Ùˆ Ø¯Ø±Ù‡ Ø§Ø·Ø±Ø§Ù Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª 
""")
st.write("""
Ù…Ù†Ø·Ù‚Ù‡ Ú©Ø¬ÙˆØ± Ø¯Ø§Ø±Ø§ÛŒ 69 Ø±ÙˆØ³ØªØ§ Ù…ÛŒ Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ø¨Ù‡ Ø¯Ù‡Ø³ØªØ§Ù† Ù‡Ø§ÛŒ Ù¾Ù†Ø¬Ú© Ø±Ø³ØªØ§Ù‚ ØŒØ²Ø§Ù†ÙˆØ³ Ø±Ø³ØªØ§Ù‚ Ùˆ  Ø´Ù‡Ø± Ú©Ø¬ÙˆØ± Ùˆ ØªÙˆØ§Ø¨Ø¹ Ú©Ø¬ÙˆØ± ØªÙ‚Ø³ÛŒÙ… Ø¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ Ø§Ù†Ø¯.
""")
st.subheader("ØªÛŒØªØ± Ø®Ø¨Ø±ÛŒ: ØµØ¯ ÙØ±ØµØª Ø´ØºÙ„ÛŒ Ø¨Ø§ Ø§ÙØªØªØ§Ø­ Ø¯Ù‡Ú©Ø¯Ù‡ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø¯Ø± Ú©Ø¬ÙˆØ± Ù†ÙˆØ´Ù‡Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
st.write("""
Ø§ÛŒÙ† Ù…Ù†Ø·Ù‚Ù‡ Ø¨Ø§ Ø¯Ø§Ø´ØªÙ† Ø¢Ø¨Ø´Ø§Ø± Ù‡Ø§ÛŒ Ù…ØªØ¹Ø¯Ø¯ ØŒ Ø¯Ù‡Ú©Ø¯Ø¯Ù‡ Ù‡Ø§ÛŒ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ùˆ ÙØ±Ø§Ù‡Ù… Ú©Ø±Ø¯Ù† Ø§Ù…Ú©Ø§Ù†Ø§Øª Ú©Ù…Ù¾ ØªÙˆØ§Ù†Ø§ÛŒÛŒ Ø¬Ø°Ø¨ Ù…Ø³Ø§ÙØ±Ø§Ù† Ø²ÛŒØ§Ø¯ÛŒ Ø±Ø§ Ø¯Ø§Ø±Ø¯.
Ø¯Ø± Ø³Ø§Ù„ Ù‡Ø§ÛŒ Ø§Ø®ÛŒØ±  Ø§ÛŒÙ† Ù†Ø§Ø­ÛŒÙ‡ Ø´Ø§Ù‡Ø¯ Ú©Ù„Ø¨Ù‡ Ø³Ø§Ø²ÛŒ Ù‡Ø§ÛŒ ÙØ±Ø§ÙˆØ§Ù†ÛŒ Ø¨ÙˆØ¯Ù‡ Ú©Ù‡ Ø§Ù…Ø±ÙˆØ²Ù‡ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ ÛŒÚ©ÛŒ Ø§Ø² Ø¬Ø°Ø§Ø¨ ØªØ±ÛŒÙ† Ù…Ú©Ø§Ù† Ù‡Ø§ÛŒ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ±Ø§Ø­Øª Ø¯Ø± Ø·Ø¨ÛŒØ¹Øª Ø¨Ú©Ø± Ø´Ù…Ø§Ù„ Ú©Ø´ÙˆØ± Ø§Ø³Øª.
Ø¯Ù‡Ú©Ø¯Ù‡ Ø²Ø§Ù†ÙˆØ³  Ø§Ø² Ù…Ø¹Ø±ÙˆÙ ØªØ±ÛŒÙ† Ø¯Ù‡Ú©Ø¯Ù‡ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø§ÛŒÙ† Ù…Ù†Ø·Ù‚Ù‡ Ø§Ø³Øª.
ÙØµÙ„ Ø¨Ù‡Ø§Ø± Ùˆ ØªØ§Ø¨Ø³ØªØ§Ù† Ø¨Ø±Ø§ÛŒ Ø³ÙØ± Ø¨Ù‡ Ø§ÛŒÙ† Ù…Ù†Ø·Ù‚Ù‡ Ø¨Ø³ÛŒØ§Ø± Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª.
""")
st.image('./images/doab-map.jpg')
st.write("""
Ø¯Ø± Ù¾Ø§ÛŒÛŒÙ† ØªØµÙˆÛŒØ±ÛŒ Ø§Ø² Ø¯Ù‡Ú©Ø¯Ù‡ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø²Ø§Ù†ÙˆØ³ Ø±Ø§ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ Ú©Ù‡ ÛŒÚ©ÛŒ Ø§Ø² Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ù‡Ú©Ø¯Ù‡ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ ÙˆØ§Ù‚Ø¹ Ø¯Ø± Ø§ÛŒÙ† Ù…Ù†Ø·Ù‚Ù‡ Ø§Ø³Øª Ùˆ Ø³Ø§Ù„Ø§Ù†Ù‡ Ù…ÛŒØ²Ø¨Ø§Ù† Ù‡Ø²Ø§Ø±Ø§Ù† Ù†ÙØ± Ú¯Ø±Ø¯Ø´Ú¯Ø± Ø§Ø² Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø§Ø³Øª.
""")
st.image('./images/village.jpg')
st.markdown("""
## Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡

Ø¯Ø± Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø§ Ú†Ù†Ø¯ÛŒÙ† Ú†Ø§Ù„Ø´ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ÛŒÙ… Ú©Ù‡ Ø¹Ø¨Ø§Ø±ØªÙ†Ø¯ Ø§Ø²:

- **Ø«Ø¨Øª Ù†Ø´Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ø¯Ø¯ Ø´Ù…Ø§Ø±Ù‡Ø§ Ø¯Ø± Ø³Ø§Ø¹Ø§ØªÛŒ Ø§Ø² Ø´Ø¨Ø§Ù†Ù‡ Ø±ÙˆØ²**: Ø§ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù…Ù†Ø¬Ø± Ø¨Ù‡ Ø§Ø² Ø¯Ø³Øª Ø¯Ø§Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù‡Ù… Ùˆ ÛŒØ§ Ù†Ø§Ø¯Ø±Ø³ØªÛŒ Ø¯Ø± ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ Ø´ÙˆØ¯.

- **Ø§Ø®ØªÙ„Ø§Ù Ø¯Ø± Ù†Ú¯Ø§Ø±Ø´ Ù†Ø§Ù… Ø´Ù‡Ø±Ù‡Ø§**: Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ Ø§Ø² Ø³Ø§Ù…Ø§Ù†Ù‡ØŒ Ù†Ø§Ù… Ø´Ù‡Ø±Ù‡Ø§ Ø¨Ù‡ Ø´Ú©Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„ÙÛŒ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³ØªØŒ Ù…Ø§Ù†Ù†Ø¯ "Ù‚Ø§Ø¦Ù… Ø´Ù‡Ø±" Ùˆ "Ù‚Ø§Ø¦Ù…Ø´Ù‡Ø±"ØŒ Ú©Ù‡ Ø§ÛŒÙ† Ø§Ù…Ø± Ø¨Ø§Ø¹Ø« Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø´Ú©Ù„ Ø¯Ø± ØªØ´Ø®ÛŒØµ Ùˆ ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø´Ø¯Ù‡ Ø§Ø³Øª.

- **ØªØ´Ø§Ø¨Ù‡ Ø§Ø³Ù…ÛŒ Ø´Ù‡Ø±Ù‡Ø§**: ÙˆØ¬ÙˆØ¯ Ø´Ù‡Ø±Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ ÛŒÚ©Ø³Ø§Ù† Ø¯Ø± Ø§Ø³ØªØ§Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù…ÙˆØ¬Ø¨ Ø§Ø´ØªØ¨Ø§Ù‡ Ø´ÙˆØ¯.

- **Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ù„Ø³ØªØ§Ù† Ø¨Ø±Ø§ÛŒ Ø³Ø§Ù„ 1402**: Ù†Ø¨ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ ØªØ£Ø«ÛŒØ± Ù…Ù†ÙÛŒ Ø¨Ø± Ú©ÛŒÙÛŒØª Ùˆ Ø¯Ù‚Øª ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ú¯Ø°Ø§Ø±Ø¯.

- **ØªÙÚ©ÛŒÚ© Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø§Ù…Ø§Ù…Ø²Ø§Ø¯Ù‡â€ŒÙ‡Ø§**: Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ØŒ Ø¯Ùˆ Ù…Ø­ÙˆØ± Ù…Ù†ØªÙ‡ÛŒ Ø¨Ù‡ Ø§Ù…Ø§Ù…Ø²Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ø¨Ø§ Ù†Ø§Ù… "Ù‡Ø§Ø´Ù…" ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´Øª Ú©Ù‡ Ø¯Ø± Ø¯Ùˆ Ø§Ø³ØªØ§Ù† Ù…ØªÙØ§ÙˆØª Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯. ØªÙÚ©ÛŒÚ© Ø¢Ù†â€ŒÙ‡Ø§ Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ú©Ø¯Ù‡Ø§ÛŒ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ù…ÛŒØ³Ø± Ù†Ø¨ÙˆØ¯ Ùˆ Ù…Ø¬Ø¨ÙˆØ± Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªÛŒ Ø´Ø¯ÛŒÙ….
            
- Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¹ÛŒØ§Ø± ØµØ­ÛŒØ­ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ù‡Ø±Ù‡Ø§ Ø¨Ù‡ Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ùˆ ØºÛŒØ±Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ
""")
st.header("Ù…Ù†Ø§Ø¨Ø¹")
st.markdown("""
- [Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ø¯Ø¯ Ø´Ù…Ø§Ø±](https://141.ir/)
- [Ø§ØªØ§Ù‚Ú©](https://www.otaghak.com/blog/about-polur-village/)
- [ÙˆØ¨Ù„Ø§Ú¯ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ø¯ÙˆØ¢Ø¨](https://www.jadidonline.com/story/12082009/frnk/galandorood)
- [ØªÛŒØªØ± Ø®Ø¨Ø±ÛŒ Ø¯ÙˆØ¢Ø¨](https://roozno.com/fa/news/32826/%D8%A7%D8%B2-%D8%AF%D9%88%D8%A2%D8%A8-%DA%A9%D8%AC%D9%88%D8%B1-%D8%AA%D8%A7-%DA%AF%D9%84%D9%86%D8%AF%D8%B1%D9%88%D8%AF-%D8%B1%D8%B4%D8%AA%D9%87%E2%80%8C%D8%A7%DB%8C-%D8%A8%D8%A7-%D8%B1%D9%88%D8%B3%D8%AA%D8%A7%D9%87%D8%A7%DB%8C-%D8%B2%DB%8C%D8%A8%D8%A7)
- [Ø¬Ø§Ø°Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ø¯Ø´Ú¯Ø±ÛŒ Ù…Ø§Ø²Ù†Ø¯Ø±Ø§Ù†](http://evaz2mn.blogfa.com/category/15/-%D9%84%DB%8C%D8%B3%D8%AA-%DA%A9%D8%A7%D9%85%D9%84-%D8%A7%D8%B3%D8%A7%D9%85%DB%8C-%D8%B1%D9%88%D8%B3%D8%AA%D8%A7%D9%87%D8%A7%DB%8C-%D9%85%D9%86%D8%B7%D9%82%D9%87-%DA%A9%D8%AC%D9%88%D8%B1-)
""")
st.header("Ø§Ø¹Ø¶Ø§ÛŒ Ú¯Ø±ÙˆÙ‡")
st.markdown("""
- Ø§Ù…ÛŒØ±Ù…Ù‡Ø¯ÛŒ Ø³Ù„ÛŒÙ…Ø§Ù†ÛŒâ€ŒÙØ± (98101747)
- Ù„ÛŒÙ„ÛŒ Ù…Ø·Ù‡Ø±ÛŒ (99171214)
- Ø±Ø§Ø¨Ø¹Ù‡ Ù¾Ø±Ù‡ÛŒØ²Ú©Ø§Ø±ÛŒ (400109413)
""")